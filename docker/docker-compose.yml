version: "3.8"

services:
  mongodb:
    image: mongo
    container_name: mongodb
    ports:
      - '27017:27017'
    volumes:
      - data:/data
    environment:
      - MONGO_INITDB_ROOT_USERNAME=root
      - MONGO_INITDB_ROOT_PASSWORD=root

  mongo-express:
    container_name: mongo-express
    image: mongo-express
    restart: always
    depends_on:
      - mongodb
    environment:
      - ME_CONFIG_MONGODB_ADMINUSERNAME=root
      - ME_CONFIG_MONGODB_ADMINPASSWORD=root
      - ME_CONFIG_MONGODB_SERVER=mongodb
    ports:
      - '5432:8081'

  zookeeper:
    image: confluentinc/cp-zookeeper:${CONFLUENT_PLATFORM_VERSION}
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000


  broker:
    image: confluentinc/cp-kafka:${CONFLUENT_PLATFORM_VERSION}
    container_name: broker
    ports:
      - "9092:9092"
      - "19092:19092"
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL_SSL:SSL
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_LISTENERS: INTERNAL://broker:9092,EXTERNAL_SSL://broker:19092
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://broker:9092,EXTERNAL_SSL://localhost:19092
      KAFKA_SSL_KEYSTORE_FILENAME: 'kafka.server.keystore.jks'
      KAFKA_SSL_KEYSTORE_CREDENTIALS: 'password'
      KAFKA_SSL_KEY_CREDENTIALS: 'password'
      KAFKA_SSL_TRUSTSTORE_FILENAME: 'kafka.server.truststore.jks'
      KAFKA_SSL_TRUSTSTORE_CREDENTIALS: 'password'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    volumes:
      - type: bind
        source: ./certificates/kafka.server.keystore.jks
        target: /etc/kafka/secrets/kafka.server.keystore.jks
      - type: bind
        source: ./certificates/kafka.server.truststore.jks
        target: /etc/kafka/secrets/kafka.server.truststore.jks
      - type: bind
        source: ./certificates/password
        target: /etc/kafka/secrets/password
      - /var/run/docker.sock:/var/run/docker.sock

  # Automatically creates required kafka topics if they were not created.
  # https://github.com/yan-khonski-it/kafka-compose
  kafka-topics-creator:
    build:
      context: kafka-topics-creator
      dockerfile: Dockerfile
    container_name: kafka-topics-creator
    depends_on:
      - zookeeper
      - broker
    environment:
      BOOTSTRAP_HOSTS: "broker:9092"
      KAFKA_TOPICS: "Statuses"

  # The 'setup-elk-stack' service runs a one-off script which initializes the
  # 'logstash_internal' and 'kibana_system' users inside Elasticsearch with the
  # values of the passwords defined in the '.env' file.
  #
  # This task is only performed during the *initial* startup of the stack. On all
  # subsequent runs, the service simply returns immediately, without performing
  # any modification to existing users.
  setup-elk-stack:
    build:
      context: setup-elk-stack
      args:
        ELK_VERSION: ${ELK_VERSION}
    init: true
    volumes:
      - type: bind
        source: setup-elk-stack
        target: /state
    environment:
      ELASTIC_PASSWORD: ${ELASTIC_PASSWORD:-}
      LOGSTASH_INTERNAL_PASSWORD: ${LOGSTASH_INTERNAL_PASSWORD:-}
      KIBANA_SYSTEM_PASSWORD: ${KIBANA_SYSTEM_PASSWORD:-}
    networks:
      - elk
    depends_on:
      - elasticsearch

  elasticsearch:
    build:
      context: elasticsearch
      args:
        ELK_VERSION: ${ELK_VERSION}
    volumes:
      - type: bind
        source: ./elasticsearch/config/elasticsearch.yml
        target: /usr/share/elasticsearch/config/elasticsearch.yml
        read_only: true
      - type: volume
        source: elasticsearch
        target: /usr/share/elasticsearch/data
    ports:
      - "9200:9200"
      - "9300:9300"
    environment:
      ES_JAVA_OPTS: -Xms512m -Xmx512m
      # Bootstrap password.
      # Used to initialize the keystore during the initial startup of
      # Elasticsearch. Ignored on subsequent runs.
      ELASTIC_PASSWORD: ${ELASTIC_PASSWORD:-}
      # Use single node discovery in order to disable production mode and avoid bootstrap checks.
      # see: https://www.elastic.co/guide/en/elasticsearch/reference/current/bootstrap-checks.html
      discovery.type: single-node
    networks:
      - elk

  logstash:
    build:
      context: logstash
      args:
        ELK_VERSION: ${ELK_VERSION}
    volumes:
      - type: bind
        source: ./logstash/config/logstash.yml
        target: /usr/share/logstash/config/logstash.yml
        read_only: true
      - type: bind
        source: ./logstash/pipeline
        target: /usr/share/logstash/pipeline
        read_only: true
    ports:
      - "5044:5044"
      - "50000:50000/tcp"
      - "50000:50000/udp"
      - "9600:9600"
    environment:
      LS_JAVA_OPTS: -Xms256m -Xmx256m
      LOGSTASH_INTERNAL_PASSWORD: ${LOGSTASH_INTERNAL_PASSWORD:-}
    networks:
      - elk
    depends_on:
      - elasticsearch

  kibana:
    build:
      context: kibana
      args:
        ELK_VERSION: ${ELK_VERSION}
    volumes:
      - type: bind
        source: ./kibana/config/kibana.yml
        target: /usr/share/kibana/config/kibana.yml
        read_only: true
    ports:
      - "5601:5601"
    environment:
      KIBANA_SYSTEM_PASSWORD: ${KIBANA_SYSTEM_PASSWORD:-}
    networks:
      - elk
    depends_on:
      - elasticsearch

networks:
  elk:
    driver: bridge

volumes:
  data: {}
  setup-elk-stack:
  elasticsearch: